{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2 - Neural Networks\n",
    "\n",
    "In this lab, we will use simple Neural Networks to classify the images from the simplified CIFAR-10 dataset. We will compare our results with those obtained with Decision Trees and Random Forests.\n",
    "\n",
    "Lab objectives\n",
    "----\n",
    "* Classification with neural networks\n",
    "* Influence of hidden layers and of the selected features on the classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, evaluate_classifier, get_hog_image\n",
    "        \n",
    "dataset = CIFAR10('./CIFAR10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the *[Multi-Layer Perceptron](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)* implementation from scikit-learn, which is only available since version 0.18. You can check which version of scikit-learn is installed by executing this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1.post1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have version 0.17 or older, please update your scikit-learn installation (for instance, with the command *pip install scikit-learn==0.19.1* in the terminal or Anaconda prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple neural network\n",
    "\n",
    "* Using the [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) from scikit-learn, create a neural network with a single hidden layer.\n",
    "* Train this network on the CIFAR dataset.\n",
    "* Using cross-validation, try to find the best possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Grid Search Completed.\n",
      "Best MLP Classifier (Logistic Regression) Found.\n",
      "Best Hyperparameters: {'activation': 'logistic', 'alpha': 1, 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "Best Training Accuracy (Cross-Validation Score): 0.7500666666666668\n",
      "MLP Classifier (Logistic Regression) Predictive Performance (Accuracy) on Test Data: 0.7476666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the HOG features\n",
    "scaler = StandardScaler()\n",
    "scaled_train_hog = scaler.fit_transform(dataset.train['hog'])\n",
    "scaled_test_hog = scaler.transform(dataset.test['hog'])\n",
    "\n",
    "\n",
    "# Define the parameter grid for the neural network (logistic regression)\n",
    "param_grid = {\n",
    "    'activation': ['logistic'],\n",
    "    'solver': ['lbfgs', 'adam', 'sgd'],\n",
    "    'alpha': [0.001, 0.01, 0.1, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Initialize MLPClassifier (logistic regression)\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(), random_state=42)\n",
    "\n",
    "# Initialize StratifiedKFold with 5 folds\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with the classifier, parameter grid, and cross-validation\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Train the grid search to find the best combination of hyperparameters\n",
    "grid_search.fit(scaled_train_hog, dataset.train['labels'])\n",
    "print(\"Grid Search Completed.\")\n",
    "# Get the best estimator (classifier) from the grid search\n",
    "best_mlp_clf = grid_search.best_estimator_\n",
    "print(\"Best MLP Classifier (Logistic Regression) Found.\")\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# Now, you can use this best classifier to make predictions on the test set\n",
    "mlp_test_preds = best_mlp_clf.predict(scaled_test_hog)\n",
    "mlp_test_accuracy = accuracy_score(dataset.test['labels'], mlp_test_preds)\n",
    "\n",
    "# Print the best training accuracy found during the cross-validation\n",
    "best_training_accuracy = grid_search.best_score_\n",
    "print(\"Best Training Accuracy (Cross-Validation Score):\", best_training_accuracy)\n",
    "\n",
    "print(\"MLP Classifier (Logistic Regression) Predictive Performance (Accuracy) on Test Data:\", mlp_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(5)\n",
    "\n",
    "for train,test in kf.split(dataset.train['hog'], dataset.train['labels']):\n",
    "    train_x = dataset.train['hog'][train]\n",
    "    train_y = dataset.train['labels'][train]\n",
    "    \n",
    "    test_x = dataset.train['hog'][test]\n",
    "    test_y = dataset.train['labels'][test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add hidden layers to the network.\n",
    "\n",
    "Try to change the structure of the network by adding hidden layers. Using cross-validation, try to find the best architecture for your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best Hyperparameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Neural Network Predictive Performance (Accuracy) on Test Data: 0.8113333333333334\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Normalize the HOG features\n",
    "scaler = StandardScaler()\n",
    "scaled_train_hog = scaler.fit_transform(dataset.train['hog'])\n",
    "scaled_test_hog = scaler.transform(dataset.test['hog'])\n",
    "\n",
    "# Define the MLPClassifier\n",
    "mlp_clf = MLPClassifier(random_state=42, max_iter=1000, early_stopping=True, n_iter_no_change=20, verbose=2)\n",
    "\n",
    "# Define the parameter grid for the neural network\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(128,), (256,), (512,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['lbfgs', 'adam', 'sgd'],\n",
    "    'alpha': [0.01 ,0.1, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the classifier, hyperparameters, and cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, cv=kf, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Train the grid search to find the best combination of hyperparameters\n",
    "grid_search.fit(scaled_train_hog, dataset.train['labels'])\n",
    "\n",
    "# Get the best estimator (classifier) from the grid search\n",
    "best_mlp_clf = grid_search.best_estimator_\n",
    "\n",
    "# Now, you can use this best classifier to make predictions on the test set\n",
    "mlp_test_preds = best_mlp_clf.predict(scaled_test_hog)\n",
    "mlp_test_accuracy = accuracy_score(dataset.test['labels'], mlp_test_preds)\n",
    "\n",
    "# Print the best parameters and test accuracy\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# Print the best training accuracy found during the cross-validation\n",
    "best_training_accuracy = grid_search.best_score_\n",
    "print(\"Best Training Accuracy (Cross-Validation Score):\", best_training_accuracy)\n",
    "# Print the test accuracy\n",
    "print(\"Neural Network Predictive Performance (Accuracy) on Test Data:\", mlp_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
